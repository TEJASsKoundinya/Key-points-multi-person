{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Pose Detection\n",
        "### (*** Individual and multi pose mapping *** )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WgsSV1IhZE4Q"
      },
      "source": [
        "#### Git cloneing for a predeveloped model approch\n",
        "[***web-link***](https://github.com/quanhua92/human-pose-estimation-opencv)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e1lmpDuRvRtG",
        "outputId": "78d8783a-452f-47b9-e187-a8a8b450a333"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WinError 2] The system cannot find the file specified: 'human-pose-estimation-opencv/'\n",
            "c:\\Users\\RIL\\Desktop\\ProjectX\\IISC\\UAV_treat_assesment\n"
          ]
        }
      ],
      "source": [
        "##!git clone https://github.com/misbah4064/human-pose-estimation-opencv.git\n",
        "%cd human-pose-estimation-opencv/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2YTltVwxaXML"
      },
      "source": [
        "### Computer-vision and required lib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZX44sl1VUklF",
        "outputId": "a9d170d0-069e-4980-b081-4628f97f1e4a"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'google.colab'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_7552/2135411905.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolab\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpatches\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcv2_imshow\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Tensorflow: \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"OpenCV: \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
          ]
        }
      ],
      "source": [
        "import cv2 as cv\n",
        "import numpy as np\n",
        "import tensorflow as tf \n",
        "from google.colab.patches import cv2_imshow\n",
        "print(\"Tensorflow: \", tf.__version__)\n",
        "print(\"OpenCV: \", cv.__version__)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bP0sPEMnaMvt"
      },
      "source": [
        "### Predefined parameters used for mapping of pose"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F5mh-FACZnNy"
      },
      "outputs": [],
      "source": [
        "BODY_PARTS = { \"Nose\": 0, \"Neck\": 1, \"RShoulder\": 2, \"RElbow\": 3, \"RWrist\": 4,\n",
        "               \"LShoulder\": 5, \"LElbow\": 6, \"LWrist\": 7, \"RHip\": 8, \"RKnee\": 9,\n",
        "               \"RAnkle\": 10, \"LHip\": 11, \"LKnee\": 12, \"LAnkle\": 13, \"REye\": 14,\n",
        "               \"LEye\": 15, \"REar\": 16, \"LEar\": 17, \"Background\": 18 }\n",
        "\n",
        "POSE_PAIRS = [ [\"Neck\", \"RShoulder\"], [\"Neck\", \"LShoulder\"], [\"RShoulder\", \"RElbow\"],\n",
        "               [\"RElbow\", \"RWrist\"], [\"LShoulder\", \"LElbow\"], [\"LElbow\", \"LWrist\"],\n",
        "               [\"Neck\", \"RHip\"], [\"RHip\", \"RKnee\"], [\"RKnee\", \"RAnkle\"], [\"Neck\", \"LHip\"],\n",
        "               [\"LHip\", \"LKnee\"], [\"LKnee\", \"LAnkle\"], [\"Neck\", \"Nose\"], [\"Nose\", \"REye\"],\n",
        "               [\"REye\", \"REar\"], [\"Nose\", \"LEye\"], [\"LEye\", \"LEar\"] ]\n",
        "\n",
        "width = 368\n",
        "height = 368\n",
        "inWidth = width\n",
        "inHeight = height"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8CUuK-LsZ3yN"
      },
      "source": [
        "### DeepNeuralNetwork generation through Tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sKrLfF9FZxrH"
      },
      "outputs": [],
      "source": [
        "net = cv.dnn.readNetFromTensorflow(\"graph_opt.pb\")\n",
        "thr = 0.2\n",
        "\n",
        "def poseDetector(frame):\n",
        "    frameWidth = frame.shape[1]\n",
        "    frameHeight = frame.shape[0]\n",
        "    \n",
        "    net.setInput(cv.dnn.blobFromImage(frame, 1.0, (inWidth, inHeight), (127.5, 127.5, 127.5), swapRB=True, crop=False))\n",
        "    out = net.forward()\n",
        "    out = out[:, :19, :, :]  # MobileNet output [1, 57, -1, -1], we only need the first 19 elements\n",
        "\n",
        "    assert(len(BODY_PARTS) == out.shape[1])\n",
        "\n",
        "    points = []\n",
        "    for i in range(len(BODY_PARTS)):\n",
        "        # Slice heatmap of corresponging body's part.\n",
        "        heatMap = out[0, i, :, :]\n",
        "\n",
        "        _, conf, _, point = cv.minMaxLoc(heatMap)\n",
        "        x = (frameWidth * point[0]) / out.shape[3]\n",
        "        y = (frameHeight * point[1]) / out.shape[2]\n",
        "        points.append((int(x), int(y)) if conf > thr else None)\n",
        "\n",
        "    for pair in POSE_PAIRS:\n",
        "        partFrom = pair[0]\n",
        "        partTo = pair[1]\n",
        "        assert(partFrom in BODY_PARTS)\n",
        "        assert(partTo in BODY_PARTS)\n",
        "\n",
        "        idFrom = BODY_PARTS[partFrom]\n",
        "        idTo = BODY_PARTS[partTo]\n",
        "\n",
        "        if points[idFrom] and points[idTo]:\n",
        "            cv.line(frame, points[idFrom], points[idTo], (0, 255, 0), 3)\n",
        "            cv.ellipse(frame, points[idFrom], (3, 3), 0, 0, 360, (0, 0, 255), cv.FILLED)\n",
        "            cv.ellipse(frame, points[idTo], (3, 3), 0, 0, 360, (0, 0, 255), cv.FILLED)\n",
        "\n",
        "    t, _ = net.getPerfProfile()\n",
        "\n",
        "    return frame"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C7RdWO-7cHdP"
      },
      "source": [
        "#### Open Pose mapping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 817
        },
        "id": "U4ay9AU2b_AY",
        "outputId": "2d7caa53-0e50-457f-b99d-842d9571aa63"
      },
      "outputs": [],
      "source": [
        "input = cv.imread(\"image.jpg\")\n",
        "output = poseDetector(input)\n",
        "cv2_imshow(output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IM48y7hMdDqi"
      },
      "source": [
        "### videomapping open pose BEST OPT FOR INDIVIDUAL MAPPING "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9JUz-5opcPy6",
        "outputId": "cfe8d802-bec5-44cd-dd52-d65849015786"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "cap = cv2.VideoCapture('/content/one.mp4')\n",
        "ret, frame = cap.read()\n",
        "frame_height, frame_width, _ = frame.shape\n",
        "out = cv2.VideoWriter('output1.avi',cv2.VideoWriter_fourcc('M','J','P','G'), 10, (frame_width,frame_height))\n",
        "print(\"Processing Video...\")\n",
        "while cap.isOpened():\n",
        "  ret, frame = cap.read()\n",
        "  if not ret:\n",
        "    out.release()\n",
        "    break\n",
        "  output = poseDetector(frame)\n",
        "  out.write(output)\n",
        "out.release()\n",
        "print(\"Done processing video\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vLDx5nD-i_15"
      },
      "source": [
        "### MULTI-open pose detection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "jZJizA9ii_Kg"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import cv2\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eiJmY7iSjWp7"
      },
      "source": [
        "Model loding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "JmOb6gKljULV"
      },
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "module 'tensorflow_hub' has no attribute 'load'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_7552/3093330638.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhub\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'https://tfhub.dev/google/movenet/multipose/lightning/1'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mmovenet\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignatures\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'serving_default'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mAttributeError\u001b[0m: module 'tensorflow_hub' has no attribute 'load'"
          ]
        }
      ],
      "source": [
        "model = hub.load('https://tfhub.dev/google/movenet/multipose/lightning/1')\n",
        "movenet = model.signatures['serving_default']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "module 'tensorflow' has no attribute 'config'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_7552/4206631851.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Optional if you are using a GPU\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mgpus\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlist_physical_devices\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'GPU'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mgpu\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mgpus\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_memory_growth\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgpu\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'config'"
          ]
        }
      ],
      "source": [
        "# Optional if you are using a GPU\n",
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "for gpu in gpus:\n",
        "    tf.config.experimental.set_memory_growth(gpu, True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iVs3RWE9mlZi"
      },
      "source": [
        "### Needs changes as imshow belongs to Jupiter \n",
        "# Deployment in Local Wont work in COLAB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "-Hv7ub8PjcQL",
        "outputId": "6b3cbf4c-11d0-4ed3-df0d-b742ef5454ff"
      },
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "module 'tensorflow' has no attribute 'image'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_7552/3193505629.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;31m# Resize image\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mframe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresize_with_pad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m384\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m640\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[0minput_img\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'image'"
          ]
        }
      ],
      "source": [
        "cap = cv2.VideoCapture('vilo.mp4')\n",
        "while cap.isOpened():\n",
        "    ret, frame = cap.read()\n",
        "    \n",
        "    # Resize image\n",
        "    img = frame.copy()\n",
        "    img = tf.image.resize_with_pad(tf.expand_dims(img, axis=0), 384,640)\n",
        "    input_img = tf.cast(img, dtype=tf.int32)\n",
        "    \n",
        "    # Detection section\n",
        "    results = movenet(input_img)\n",
        "    keypoints_with_scores = results['output_0'].numpy()[:,:,:51].reshape((6,17,3))\n",
        "    \n",
        "    # Render keypoints \n",
        "    loop_through_people(frame, keypoints_with_scores, EDGES, 0.1)\n",
        "    \n",
        "    cv2.imshow('Movenet Multipose', frame)\n",
        "    \n",
        "    if cv2.waitKey(10) & 0xFF==ord('q'):\n",
        "        break\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "JY3GLxYZjutr"
      },
      "outputs": [],
      "source": [
        "def loop_through_people(frame, keypoints_with_scores, edges, confidence_threshold):\n",
        "    for person in keypoints_with_scores:\n",
        "        draw_connections(frame, person, edges, confidence_threshold)\n",
        "        draw_keypoints(frame, person, confidence_threshold)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "X8RVD2xPjvlV"
      },
      "outputs": [],
      "source": [
        "def draw_keypoints(frame, keypoints, confidence_threshold):\n",
        "    y, x, c = frame.shape\n",
        "    shaped = np.squeeze(np.multiply(keypoints, [y,x,1]))\n",
        "    \n",
        "    for kp in shaped:\n",
        "        ky, kx, kp_conf = kp\n",
        "        if kp_conf > confidence_threshold:\n",
        "            cv2.circle(frame, (int(kx), int(ky)), 6, (0,255,0), -1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "6rIIy9rij1uD"
      },
      "outputs": [],
      "source": [
        "EDGES = {\n",
        "    (0, 1): 'm',\n",
        "    (0, 2): 'c',\n",
        "    (1, 3): 'm',\n",
        "    (2, 4): 'c',\n",
        "    (0, 5): 'm',\n",
        "    (0, 6): 'c',\n",
        "    (5, 7): 'm',\n",
        "    (7, 9): 'm',\n",
        "    (6, 8): 'c',\n",
        "    (8, 10): 'c',\n",
        "    (5, 6): 'y',\n",
        "    (5, 11): 'm',\n",
        "    (6, 12): 'c',\n",
        "    (11, 12): 'y',\n",
        "    (11, 13): 'm',\n",
        "    (13, 15): 'm',\n",
        "    (12, 14): 'c',\n",
        "    (14, 16): 'c'\n",
        "}\n",
        "def draw_connections(frame, keypoints, edges, confidence_threshold):\n",
        "    y, x, c = frame.shape\n",
        "    shaped = np.squeeze(np.multiply(keypoints, [y,x,1]))\n",
        "    \n",
        "    for edge, color in edges.items():\n",
        "        p1, p2 = edge\n",
        "        y1, x1, c1 = shaped[p1]\n",
        "        y2, x2, c2 = shaped[p2]\n",
        "        \n",
        "        if (c1 > confidence_threshold) & (c2 > confidence_threshold):      \n",
        "            cv2.line(frame, (int(x1), int(y1)), (int(x2), int(y2)), (0,0,255), 4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\RIL\\anaconda3\\envs\\NewTensorflow\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
            "c:\\Users\\RIL\\anaconda3\\envs\\NewTensorflow\\lib\\site-packages\\numpy\\.libs\\libopenblas.EL2C6PLE4ZYW3ECEVIV3OXXGRN2NRFM2.gfortran-win_amd64.dll\n",
            "c:\\Users\\RIL\\anaconda3\\envs\\NewTensorflow\\lib\\site-packages\\numpy\\.libs\\libopenblas.XWYDX2IKJW2NMTWSFYNGFUWKQU3LYTCZ.gfortran-win_amd64.dll\n",
            "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "my_img_1 = np.zeros((512, 512, 1), dtype = \"uint8\")\n",
        "cv2.imshow('Single Channel Window', my_img_1)\n",
        "my_img_3 = np.zeros((512, 512, 3), dtype = \"uint8\")\n",
        "cv2.imshow('3 Channel Window', my_img_3)\n",
        "cv2.waitKey(0)\n",
        "cv2.destroyAllWindows()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "img1 = cv2.imread('tests/data/coco/000000000785.jpg')\n",
        "mask = np.zeros(img1.shape[:2],np.uint8)\n",
        "bgdModel = np.zeros((1,65),np.float64)\n",
        "fgdModel = np.zeros((1,65),np.float64)\n",
        "rect = (10,10,360,480)\n",
        "cv2.grabCut(img1,mask,rect,bgdModel,fgdModel,5,cv2.GC_INIT_WITH_RECT)\n",
        "mask2 = np.where((mask==2)|(mask==0),0,255).astype('uint8')\n",
        "img1 = img1*mask2[:,:,np.newaxis]\n",
        "plt.imshow(img1),plt.colorbar(),plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "PoseDetection.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.8.12 ('NewTensorflow')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    },
    "vscode": {
      "interpreter": {
        "hash": "c23ebc921ba0aca5010e6414f449f9f221bf5cfe4e99e910c0785f6899776a41"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
